{"categories":[{"title":"Syntax","uri":"https://zhoujb22.github.io/categories/syntax/"},{"title":"Themes","uri":"https://zhoujb22.github.io/categories/themes/"}],"posts":[{"content":"一、阿尔法信号构建要求 基本特征 理论简洁且数学表达式简单 代码实现优雅 具有较高的夏普比率（风险调整后收益） 稳定性要求 对数据和参数微调不敏感 适用于多股票池、多区域市场 能够持续创造新高利润 二、阿尔法开发流程 迭代循环框架 数据变量挖掘 变量变化建模 构建持仓量数学表达式 历史回测验证 通过验证则纳入信号池 三、阿尔法生命周期规律 市场博弈机制：盈利策略吸引资金→策略容量饱和→收益摊薄→策略失效→新机会产生 有效周期关键： 历史验证时长 资金流入规模 市场结构变化速度 市场动态平衡 资金流动与策略有效性呈现周期性变化 新旧策略交替维持市场活力 阿尔法信号在市场演进中持续更新迭代 四、阿尔法评估体系 核心评价指标 信息比率 = 每日损益均值 / 标准差 夏普比率（风险调整后收益） 最大回撤幅度 策略独特性（与其他信号相关性\u0026lt;0.5） 回测验证要点 样本外测试有效性高 and 样本内表现好 极端值对模型的破坏性检验 交易成本敏感性测试 五、历史市场认知误区 核心观点 历史市场并非更易交易 过去赚钱同样具有挑战 现在去看历史，会觉得当时的市场比现在更加容易交易，这是因为如下几个原因第一，你当时不会有现在的领悟，第二你现在拥有之前无法得到的数据，第三，你当时没有现在这么强大的计算能力和技术，因此每个十年都有他自己的市场和独特的市场机会，这取决于阿尔法开发者是否能够有当时的技术数据寻找的市场机会。反观历史，诸如过去预测市场和赚钱更容易这样的想法是错误的。\n六、止损 有这样一个悖论，只有一个理论一直适用，就是没有理由一直适用。\n理论与规则的局限：任何理论或规则都不是绝对适用的，它们只是帮助我们理解现实的工具，但永远无法完全反映现实的复杂性。因此，我们不能迷信单一的理论或规则，而应保持开放的态度，关注全局。 止损的重要性：止损意味着在规则失效时及时放弃，避免继续依赖无效的规则。判断一个规则是否有效的标准是它当前是否能够带来收益。如果规则失效，应及时停止使用，而不是盲目坚持。 多样化策略：为了避免单一规则的局限性，应采用多种规则和策略，并根据实际情况灵活调整。同时，要提前计划如何在低成本的情况下改变策略，并及时停止表现不佳的策略。 判断策略有效性的标准：如果一个策略的表现超出预期历史收益范围，可能表现为回撤过大、收益风险比下降或出现历史数据之外的结果，这表明策略可能已经失效，需要及时止损。 接受不确定性：我们无法完全掌握所有信息，因此必须接受现实的不确定性。通过广泛思考和不断调整规则，我们可以逐渐接近对事物的深入理解，但永远无法达到完全掌握。 七、Alpha评估方法 模拟与量化： 通过模拟（如回撤模拟）来量化交易策略的结果，例如计算信息比率（Information Ratio） 将阿尔法的预测与交易策略配对，假设阿尔法预测的是策略中特定资产的仓位变化，而交易行为则基于阿尔法预测的变化。 局限性： 阿尔法主要用于预测收益，而非直接指导交易，因此可能难以找到完全匹配的策略。 模拟过程中成本较低甚至无成本，但在实际应用中可能存在偏差。 评估指标： 信息比率：阿尔法收益与基准收益标准差的比值，用于衡量阿尔法预测的持续性和有效性。结合观察时间窗口，可以判断阿尔法信号是真实的预测还是随机噪声。 利润分析：根据交易规模划分阿尔法创造的利润，评估其对交易成本的敏感性。高利润阿尔法受交易成本影响较小，而低利润阿尔法通常不适合作为独立策略使用，除非与其他阿尔法结合使用。 独特性：在阿尔法信号池中，信号与其他信号的相关性越低，其独特性越高，价值越大。低相关性表明阿尔法信号提供了新的信息，而非重复现有信号。 Alpha稳健性 样本内外表现一致性：样本内信息比率与样本外相近 参数鲁棒性：在主要参数区间（如半衰期20-60日）表现稳定 低维护成本：如年化换手率＜100倍，季度调仓次数＜5次 逻辑可解释性：因子经济学意义明确，归因分析清晰 跨市场有效性：在A股、港股、美股等主要市场均有正向表现 风险可控性：历史最大回撤＜15%，Calmar比率 回撤恢复能力：平均回撤修复周期 资金容量：单策略管理规模 八、Alpha提升方法 避免损失的方式之一是开发行业中性化策略。这种策略使得不管正在发生的是正面还是负面的事件，资产都没有很大的下跌风险。行业中性化策略是指投入一个行业的头寸加总为零及行业中所有的股票的持仓金额加总为零。\n得到简单的阿尔法公式后，可以计算年化收益率、信息比率、最大回撤、盈利比、日换手率、每美元的交易利润；之后，可以增加如行业中性化的限制条件，或者使用相对大小作为预测指标等级为相对的阿法值， 我们还可以通过衰减运算来降低换手率及对阿尔法处于某时间窗口的平均值。\n九、关于风险因子 我们发现，任何阿尔法策略在实践中往往都会无意间引入某些风险因子。例如，尽管某些阿尔法信号在构建过程中未直接使用价格信息，但由于市场行为的复杂性，它们仍可能受到市场动态的影响。以新闻情绪为例，虽然新闻撰写者并不会刻意基于股价撰写文章，但当股票价格飙升时，新闻报道往往带有更强的乐观情绪。因此，从新闻情绪中提取的阿尔法信号可能隐含着惯性效应，这使其与动量因子存在一定关联。\n这些风险因子可能在未来持续提供正向的风险溢价，但在研究过程中，我们需要注意以下几个问题：\n风险因子的可预测性及其收益的可持续性\n由于这些因子的存在较为公开，市场上的聪明资金会不断涌入并利用它们，因此它们的夏普比率及风险调整后的回报不可能长期维持较高水平。市场竞争会使得收益逐渐压缩，直至该因子不再提供足够的吸引力。 市场流动性与风险因子的影响\n一些风险因子（如市值、流动性）要求市场中多空资金流向存在较大不均衡。然而，在实际交易中，投资者通常希望市场流动性相对均衡，以便顺利建仓和清仓。这种不均衡可能会带来额外的交易成本，并在市场危机时造成更严重的流动性冲击，影响投资者的风险管理能力。 风险因子的波动性与宏观趋势的影响\n许多风险因子的收益波动性在不同市场环境下可能存在较大差异，特别是在宏观经济周期变化时。例如，在市场下行期，这些因子可能经历长期回撤。此外，部分风险因子可能会被金融机构包装为另类贝塔产品（Alternative Beta Products），进一步加剧其未来的波动性。2009年，市场回撤导致一个简单的惯性因子进入长期回撤阶段，这表明某些风险因子的表现并不稳定。 市场共振效应与系统性风险\n由于许多量化投资策略广泛使用相同的风险因子，当市场出现突发事件时，集中持仓可能引发剧烈的连锁反应。例如，在2007年8月的量化危机中，部分投资者大规模清仓，导致一些常见的量化风险因子遭受严重损失。在这种情况下，市场的跟风行为可能加剧危机，使得市场短时间内出现剧烈波动。因此，投资者应尽量采用与市场主流不同的策略，并控制对通用风险因子的敞口，以降低潜在的系统性风险。 综上所述，尽管经过充分研究的市场效应可能在长期内继续提供正向收益，但这些收益可能既是对风险的合理补偿，也可能是市场非理性行为的产物。因此，在研究过程中，我们更倾向于将这些因素视为风险因子，而非真正的阿尔法。在构建新的阿尔法策略时，我们希望尽量减少风险因子的影响。在消除风险因子后，应该评估阿尔法的剩余贡献，一个优秀的阿尔法策略在剔除风险因子影响后，仍然应当具备较高的夏普比率和优异的风险调整收益。尽管在某些情况下，单位货币收益可能有所下降，但从长期来看，这种优化能够提升策略的稳定性和可持续性。\n十、关于IC和IR 两种IC： Rank IC 排序相关系数 Pearson IC 线性相关系数 三种IR： 传统信息比率: 因子超额收益率/超额收益率标准差 因子信息比率（基于 IC）: IC mean / IC std 《Active Portfolio Management》（Grinold \u0026amp; Kahn）提出 $IR = IC \\cdot \\sqrt{\\text{Breadth}}$（Breadth 为独立预测次数）。 WorldQuant: 信息比率IR是每日损益的平均值除以每日损益的标准差，用来衡量正确或正确组合风险调整后的收益是信息系数 ×交易次数的平方根。 我们认为高的信息比率能够获得较好的风险调整收益。 主动型的投资经理会交易的更频繁，他们每天都多次调整 证券组合。交易的频率越高，越容易呈现统计特征。我们引入高斯分布或正态分布概念，当我们把N个独立分布的正态分布相加时，相对于原来的概率分布正态分布的均值一样，但是标准差只有根号N分之一 。相同的IC四倍的交易频率，而是原来的两倍。 这三个 IR 不是完全相同的度量方式： 传统 IR = 实际回测结果。 因子 IR = 因子预测稳定性。 Grinold-Kahn IR = 理论上可实现的超额收益能力。 Grinold-Kahn IR 数量级取决于交易频率： 高频交易（大 ${Breadth}$）能显著提高 IR。 低频选股策略依赖高 IC，而不是 Breadth。 实际应用： 基金经理/投资组合 → 用 传统 IR 评价表现。 量化因子研究 → 用 因子 IR 评估稳定性。 策略设计 → 用 Grinold-Kahn IR 评估理论可行性。 💡 如果你的策略是高频交易，即使 IC 很低，Breadth 足够大，IR 仍然可能很高。这就是量化高频交易的优势所在！ 🚀 十一、Alpha与基本面分析 基本面分析是证券投资分析方法的基石，显然是阿尔法策略研究中的一个很重要的方向。股票的基本面分析，是通过挖掘可能会影响公司实际业务和未来前景的潜在因素，从而判断证券内在价值的技术手段。从广义上来说，基本面分析是指分析一个金融实体的经济状况，而不是特意分析其价格走势。可以从行业或者经济整体情况分析，而不是单一的分析一只股票。 相对于基本面分析，另一种主要的证券分析方法，同时也是阿尔法策略中的一个主要方向技术面分析，主要考虑证券价格和交易量的变化。\n基本面分析，既可以是定性分析，也可以是定量分析。很多实证研究都试图通过发现财务报表数据与证券价格之间的关系，来提高基本面分析的准确性，除财务报表中的 常见科目外，一些标准格式外的相关信息也会在辅助中说明。季度电话会议也是我们了解公司披露信息的手段；由投资银行或证券公司等卖方提供的分析报告也是一种信息来源。由于基本面数据更新频率较低，基本面相关的阿尔法信号，相对于其他类似量价的信号，其换手率和股票覆盖率都很低。 另一方面，基本面信息反应的是长期的股价。基于基本面的阿尔法信号的累积收益，通常集中发生在财务公告的前后，然后在信息披露一年后逐渐平稳。也就是说大部分超额收益是和公司前一年利润变化相关的。\n基本面分析也给我们提供了一些股票分类思路。 例如，我们可以根据公司的基本面状况，把股票分为价值型和成长型股票。价值型股票通常指的是股价低，市盈率低，高股票分红的企业。成长型股票相反，这些基于基本面的分类方法可以帮助我们更好地理解不同类型股票的市场表现，从而设计出更好的阿尔法信号。\n十二、Alpha与换手率 换手率：总的交易量除以持有的总仓位。\n低换手率不一定意味着低收益， 换手率和收益必须找到一个平衡。某些触发频率较低的信号，通过平滑曲线（再次降低触发频率）的方法还可以提高表现。去极值和衰减因子能够降低换手率，可以用来防止对信息太过敏感，从而造成预测值不必要的改变，最终结果取决于阿尔法策略如何设计。但不管结果如何，理解在不同换手率下阿尔法策略的表现，能够帮助我们获得交易灵感，我们宁愿选择加杠杆而不太影响收益的阿尔法策略，也不会选择为稍微降低换手率而损失所有收益的策略。\n十三、Alpha与证券组合风险的关系 要想确定最优策略，从而持续获取尽可能多的收益需要一定的技巧。阿尔法可以反映出一个基金经理在不提高风险的前提下，扩大证券组合收益的能力。在不增加风险的条件下增加收益并不意味着阿尔法对于收益来说是一种没有风险的源。 当阿尔法从与证券组合里的风险正交的源获得收益，他对风险组合具有多元化效应。真正的阿尔法并不能对证券组合里已有的风险产生杠杆作用，他只能增加不同的风险源。\n我们需要根据初期的风险水平和收益来确定一个阿尔法是否能够增加价值，这就意味着阿尔法对背景信息有很高的依赖度，也就是说一个阿尔法可能增加某种证券组合的价值，却对另一种证券组合无效。 我们可以将证券组合看作风险的综合体，每一种收益都衍生于其对应的风险源。两种证券组合的不同效果取决于风控经理挖掘数据中风险源和收益源的数量。 极端情况下，一部分风控经理坚持倾向于关注少数几种风险，尝试通过增加赌注去增加价值，通过平凡的交易弥补多元化投资的不足。另一部分风控经理则尽量避免市场择时或者因子择时， 不会在少量因子上下大赌注，他们通过在证券组合中引入更多的风险源来进行风险管理。在介于两者之间的证券经理，要么更偏好与将两种操作方式结合起来，要么被指定必须要求满足特定的要求，在这些要求中，有些会限制他们可以涉及的风险种类，有些会控制他们在每种风险源上设置的权重。例如，证券经理可能被要求他的证券组合里不可以承担任何利率风险，这样的话，他就必须确保利率风险因子的敞口为零。这可以保证不论这个因子怎么变化，它的证券组合都能不受影响，但是这也迫使证券经理放弃与之相关的收益。为了弥补收益上的损失，证券经理可能在其证券阻合中的其他因子上冒更大的风险，或者创造阿尔法。\n很多风险源已经被广泛认识，并理解。在极端的情况下，证券经理可能会被要求在其证券组合中去除大部分甚至是全部的已知风险。为了依然可以产生收益证券经历，就不得不对其他市场参与者上不了解的、或尚未被广泛利用的风险源进行研究。而这就是创造阿尔法工作的意义：寻找别人不了解的或与其他证券经理不同的风险源和收益（理想情况下为正交的）。 这种阿尔法的衰减速度很慢，可以为发现它的人带来长期利润据。又由于其特殊性，与之收益相关的风险，不会对证券组合中已有风险产生杠杆作用，只是会使风险更加多元化。在效果上，每个阿尔法都可以提供一种新的收益流，稀释证券组合中的风险压力，这样单个风险就不会对证券组合产生重大影响。\n已被广泛知晓的风险很容易受到拥挤效应或从众效应的影响，对证券经理的证券组合造成重大威胁。只要其他市场参与者忽略他这种因子的风险就会很小。然而一旦他的使用变得过度拥挤，其风险——收益曲线就会发生剧烈变化。随着追逐某一因子的资本的增加，证券经理从该种因子中收获的收益就会减少，而采用该种风险的证券组合面临的风险值就会增大。这是因为在某些时刻，资本的撤出更可能大于资本的注入，而且通常的情况是，这种撤出会像暴雨一样突然而至，而资本的注入通常是个缓慢的长期的过程。这就是为什么很难选择退出某种因子恰当时机的原因，同时也是为什么关注少数几个因子的证券组合比多元化证券组合波动性更大的原因。 恐惧对情绪的驱动力比贪婪大更多，因此抛售发生很突然，几乎不给证券经理任何预警或反应的时间。\n另一方面，未知因子不应该被等头论之。 未知因子的风险敞口不应该被严格限制，因为他们发生拥挤的概率并不高。因此对这些因子增大风险敞口有益于优化证券组合，因为收益并没有在其他市场参与者直接进行分配，又因为参与者少，所以引发抛售的情况也很少。然而在实践过程中很难确定，究竟有谁知道并在使用这样的阿尔法，以及他们在上面究竟有多少资本在流动。 因此，证券经理通过使用尽量多的不同的阿尔法来稀释这些风险是非常明智的。\n对于有无风险意识的证券经理来说，在理想的证券组合中，该尽量将那些广为人知的风险因子的风险压力贝塔控制为零，同时应该尽量多的发现新的位置，因此，阿尔法应当以所有已知因子正交以使其不受其他市场参与者的市场行为的影响，并且不同阿尔法之间也要互相正交，从而确保正确组合具有最大的风险多元性。这样的证券组合的收益将全部来自于阿尔法成分在很大程度上其余市场参与者并不能从中获益。\n在现实中，很少有对已知风险敞口为零的正确组合。正确组合中的因子，无论是否众所周知，彼此之间都几乎不可能完全正交。因此，证券经理的阿尔法通常是以下两种策略的结合：1️⃣：因子择时（根据时机调整不同风险因子的敞口）；2️⃣： 掌握其他市场参与者未知的风险源。\n在因子择时的情况下，其他市场参与者虽然不太可能知道证券经理的阿尔法具体是什么，但是他的阿尔法只是一些已知因子的组合。正确经理对风险压力可以进行更好的组合，使得每种风险，因此可以获得尽量多的正向影响，同时尽量减少负面影响。这种类型的阿尔法可以通过改变操作时机和频率等方式重新建立平衡的行为，对正确组合中已有的风险敞口进行调整。 使用这种类型的阿尔法需要付出一定的代价。原因很简单，如果一种阿尔法提高交易频率或规模，那么这种证券组合的可测量性及证券经理对其的控制能力就会受到严重影响。一般情况下，正确经理进行因子择时的次数越多，就越不可能扩大其证券组合的规模，因为频繁或者大额的转手可能对收益有负面影响，原因在于转手需要应的手续费，而且价格影响比较大。\n最有价值的是发现不会对有风险源产生杠杆作用的阿尔法，这样可以做到风险多元化，但是这些阿尔法很难被发现，尤其在已知风险因子的数量已经相当大的情况下。为了发现这种阿尔法，就必须对已知风险因子的正交空间有意识的进行深度研究。这个过程代价很大，产出可能很小。然而即使这样，也是值得的。这种阿尔法而除了会产生收益之外，还会使证券组合实现真正的多元化。这种阿尔法的绝对回报，虽然很诱人，但其真正价值在于发现一种完全不同的风险源，可以为证券组合带来不同于其他风险源的收益。\n考虑到阿尔法与证券组合风险之间的动态进化关系，对于寻找阿尔法或应用阿尔法构建证券组合的从业者来说，主要评估阿尔法的绩效之外，还要对阿尔法在以下关键性问题上的表现进行评估：第一、他真的与众不同吗？如果阿尔法不与已经知道的风险因子或其他证券组合中的阿尔法正交，那么，这个阿尔法就会对风险产生放大作用。这种重叠越低越好，证券经历至少应该认识到这个重叠度的存在，并且清晰了解每个因子上承担了多大的风险。第二，谁不知道他？有风险带来的收益必须不被其他市场参与者知道，就算有人知道，证券经理需要做的也是尽可能的减小敞口。 第三，他合理吗？如果一个阿尔法从不符合市场行为的活动中获得收益，那么这个阿尔法基本上是没有用的。如果一个阿尔法交易的全是非流动性的资产，那么他怎么会产生收益呢？ 第四，他能规模化吗？对因子择时依赖度很高的阿尔法非常难操作，原因在于这种阿尔法想要成功的话，必须要有更多市场参与者的配合。你需要一个交易伙伴执行的办法。各主要的是你对这样的人是否存在以及他叫将采取什么样的行动，必须判断正确。这种情况发生的越频繁，你需要进行的交易量就越大，你从阿尔法中获益的机会就越小。因为，你希望交易的条件可能不会一直存在或者其可能会与你的假设不符。第五，他会持久吗？好的阿尔法必须不能被出街市场参与者直觉性的感受到，最好对他们没有 吸引力，但是对于进阶型市场参与者来说，他是非直觉性的有逻辑的。这样就可以通过时间差减少其他市场参与者对收益的瓜分。即使是一个不容易被察觉到的因子，也可能迅速地被其他人发现从 高收益低风险源变成低收益高风险源。\n十四、风险与回撤 在这里，我们只 简要的讨论在设计阿尔法时的风险。\n投资多元化程度可以降低阿尔法或证券组合的风险。在头寸集中度可控的前提下，使用的金融工具种类越多，多元化效果越好。然而，我们扩大标地的选择区域的同时，也会引入其他风险。这些风险包括在相同的阿尔法内对不同国家和不同货币体系的风险敞口。应当认真考虑谨慎对待这些风险，有时还要通过中性化方法来降低这些风险。同样，，使用丰富的资产种类，如期货、股票、债券等，也会提高多元化程度。\n关于风险，需要指出的一点是，一个好的阿尔法尝试区分股票中的胜者和败者，从而建立多空组合，但是这并不是百分之百会发生的。我们假设有一个阿尔法可以区分胜者和败者，而且这些股票的胜败趋势长期稳定。如果这种情况真的发生了，那么这个阿尔法对这些股票的价格趋势就有了风险敞口。有时，交易某只股票赚取到一定的收益后，阿尔法会减弱这支股票的持仓信号，而不是持续跟进这只股票的趋势，直到产生回撤。同样的事情会发生在利用阿尔法预先设置止损的情况下。如果样本空间不够广的话，以上这些技术就尤为重要了。\n回撤是阿尔法损失相对其分值的百分比，我们在回测时通常关心的是回撤的两个重要指标： 阿尔法的历史最大回撤以及每年最大回撤和最大回撤历时。\n以下一些简单的最小化风险的方法可以帮助你将回车量最小化：最小化所有单个证券的最大敞口；最小化所有相似证券组合中的最大敞口；最小化对一般阿尔法因子的敞口；最小化对整个市场的敞口。\n十五、数据与Alpha设计‘ 数据在设计的过程中，扮演了核心角色。首先，我们需要利用基础数据运行模拟。基础数据是指股票价格和交易量。不论你想要对什么类型的阿尔法做回测，你都需要利用这些基础数据计算收益率下普比率及换手率 等指标。如果没有这些指标，我们永远也不会知道这个阿尔法是好还是坏。其次，数据本身对阿尔法具有启发作用。例如，你可以画出某些股票的价格交易量图表，节约历史上是否有类似情况发生，你也可以用量价数据进行技术分析。\n对于阿尔法研究人员来说，寻找新的数据是非常重要的技能。人们通常喜欢绩效好、相关性低的阿尔法。新的数据及可以达成上述目标。如果我们能在原始数据的基础上得到另一种数据就可以从不同的角度审视目标公司，增强原始信号，获得更优质的信号。 同时我们总想创造出相关度较低的阿法提高阿尔法信号是多元性。然而，尽管构建阿尔法的方法不同，但有时，基于同一个数据的阿尔法信号也会表现出高度的相关性。这是由于使用了相同的数据，阿尔法信号呈现出天然的相关性。\n以下是几种数据的来源方法： 第一、文献中的数据，数据的来源有很多，最常用的来源是学术文献。论文中，我们可以查到作者们在研究中使用的各种各样的数据，可以参考他们的使用；我们也可以利用互联网上的公共数据，但是越鲜为人知的数据可利用价值就越高，但是如果一些常用的数据从来没有用于价格预测，那么即使很多人都知道，他们仍然具有被使用的价值。 第二、供应商处的数据。 数据是非常有价值的信息，因此售卖数据也是一门生意。\n作为阿尔法研究人员，不论什么时候，只要拿到新数据，首先要做的不是利用数据检验阿法信号，而是检验数据的可用性。 数据的发布时间是个非常重要的因素，任何没有时间戳的数据就是没用的数据。这是因为如果不知道数据创建的时间点，我们就不可能有效的了解他的进程，只能盲目的使用它。如果我们尝试使用当前还不可用的数据，即未来数据，我们会引入前瞻性偏差，将使得阿尔法效果惊人。\n数据可能产生的另一个问题是幸存者偏差。例如，数据上提供一组阿尔法模型，，测试的时候绩效很好，但是这并不意味着这个阿尔法模型在未来也会表现很好。因为我们不知道数据上开发了多少模型，这些模型是基于什么建立的。如果数据供应商是建立了1000个模型，只有一个成功了，我们就可能会面对幸存者偏差。 这个偏差是由数据上面入的，是超出我们的控制范围的。在这种情况下，一些样本外测的数据就更有用了。因此样本外侧是非常有用的，如果阿尔法在样本外侧绩效表现依然很好的话，则我们可以认为阿尔法的稳定性很好，因为测试是在不受控制的样本库中进行的。\n我们在进行阿尔法设计的时候，应该对数据的完整性进行检查。在进行历史模拟时，哪怕一个坏数据也能破坏整个尔法信号。在现实生产中，如果你认为数据总是正确的，那么你将面临很大的风险，因为错误的数据可能会彻底扭曲阿尔法信号，导致巨大的损失。\n严谨的阿法研究也需要对数据进行深入的理解。我们一定要理解数据，这样才能更好地利用它。\n第十六、统计套利，过度拟合与Alpha的多样性 阿尔法可以直接预测股票市场吗？或者更确切的说，我们可以预测苹果公司的股价吗？我们很可能预测不到，统计套利的本质，就是我们只能在统计意义上进行预测。统计套利的关键假设认为金融商品价格是有规律的，通过研究历史数据可以发现这些规律，并用规律预测未来。正确的价格由多种规律驱动，对于特定时刻的特定金融产品，这些规律并非必然适用。但是，真正驱动价格的规律或者基于价格驱动规律的好的阿尔法，应该在我们研究的交易日中表现出具有统计意义的预测性。\n在量化中，利用统计套利寻找阿尔法的过程具有过度和或发现违背价格驱动规律的风险。例如，代码中还有C的股票通常在星期三上涨，这样的阿尔法很有可能是不值得投资的阿尔法，即使他在过去可能表现出了盈利性。\n虽然单纯的利益用数字对数字进行挖掘，可以发现一些写著的效果，但更为重要的是深入理解在阿尔法的构造过程中潜在的价格驱动规律。采用合适的实现方法，将驱动规律转化为阿尔法。金融商品的价格由多种因素驱动，如交易微结构、基本面固执、 投资心理等。因此，能够用于构建阿尔法的价格驱动规律很多。此外，基于同样的价格驱动规律利用不同的实现方式，也可以构建不同的阿尔法。例如均值回归规律，其中关于均值的算法有很多种，关于回归的定义也不止一个，这样就可以构造出不同的阿尔法，这些阿尔法都可以表现为盈利性。\n第十七、提高Alpha稳定性的方法 稳定的阿尔法策略应该具有如下特征： 第一、不随着交易环境的变化而变化：阿尔法策略应该体现统计的属性，他独立于整体交易市场的选择。或者说，我们不希望我们的阿尔法策略依赖于某个进入工具或者一组工具。这一约束平凡的被市场所强加，级别应包括政策调整、客户偏好、流动性降低、做空等。\n第二、在极端市场下的稳定性：阿尔法信号的所有指标都不应该出现极具下跌的情形。\n改善稳定性的简单方法： 第一、排序法：\n划分等级：划分等级按照某种排序方法，将一个向量的元素替换为它们的序号，例如从零到向量长度 -1， 通常将所有向量元素除以向量长度-1进行归一化。如果两个因子值相同，那么他们应该具有相同的序号，该序号等于它们对应位置的均值。 分位点近似：分位点就是对一个随机变量的累积分函数以固定间隔分为采样得到的点集聚。。将有序数据分别规律，在有相同数据的数据及中被称为Q分为法；分为点就是连续数据子集之间边界的数据值。举例来说， 我们熟知的最小平方回归法，既最小二乘法，对于非平稳、非线性输入可能是不稳定的。然而，它可以被最小分为平方LQS所代替。 其目标是使平方差的某些分位数最小化。最常用的LQS方法是使中位数平方最小化。 第二、 向正态分布逼近： 费希尔变化公式。 Z-Score 第三、 限制性方法： 截取法：限制每支股票投资资金在总投资资金上所占的最大比例。 温莎化：温莎化是统计数据的变形，通过限制统计数据的极值来减少假的极端值带来的影响。 改善稳定性的高级方法： 当我们要从一个 有限数据集中预估数值时，重采样方法会比较有效，比如自引导法、交叉验证法等。\nBertsimas等人在2004年曾提到：提高稳定性，可以在极端市场环境下显著改善阿尔法的测评指标。\n第十八、自动化搜寻Alpha 自动化的阿尔法搜寻就是利用计算机算法从海量云数据中找到阿尔法信号。只要使用得到它可以协助提高阿尔法搜寻的效率，一日之内即可得出数迁移记的阿尔法。但是，找到的所有信号并非都是真的阿尔法。很多看起来很棒的阿尔法信号都是噪声，而不具备任何预测能力。因此必须在输入准备、搜寻算法、信号测试算法等方面做出特别努力，以改善这些阿尔法 的稳定性。\n总体来说，一个自动化搜寻有三个组成部分：输入数据搜寻算法以及信号测试。首先，我们选择一组有意义的财务数据作为输入预测变量。接下来对输入预测变量进行预处理以去除极端值，再输入搜寻算法。其次我们选择一个目标函数Y，用来表征未来的股票回报或者其辩题。再次， 适配算法会为一组选择的函数族找到一组参数，最简单例子是线性函数，依次来模拟目标函数。最后，对适配好的函数进行稳定性测试。\n在数据准备和信号测试中，有一些技巧可以使阿尔法更加可靠：第一、 将输入数据比例化是一个好方法。好的股票收益预测指标应该对所有股票具备同一性和可比性。因此原始财务数据，通常因为在不同股票上不具备可比性，所以不是一个好的预测指标。比例化的两个方法的第一可以用该变量的当前值比其历史值；第二可以将该变量比上同类的一个相似变量，例如既收入和营收的比值， 净收入和营收对于所有股票都是有可比性的。 第二、输入数据，不应该取自太多的类别。给函数添加太多的输入变量会使其在样本内侧有很好的表现，但是通常会因为过渡你和而导致其损失预测能力。配置很多变量可能会导致过度拟合，但是适配来自很多不同类别的变量则更糟糕。这里类别只在数据的类型和来源。 每个类别的数据有其自身特征频率，例如基本面数据通常呈现出清晰的季度周期性，价格交易量分布稳定，而内幕交易数据通常是随机的。如果模型包含很很多来自不同类别的数据，那么其复杂度将大大提高，而该模型也将对数据中的噪声更加敏感。第三、测试周期并非越长越好。 在选择输入数据的长度时需要折中。如果测试周期太短，我们得到的数据太少，就会对计算结果信心不足。如果测试周期太长，驱动逻辑可能已经发生了变化，就会让计算结果变得不可靠。 第四、敏感性测试和重要性测试很重要。一个好的尔法信号应该对噪声不敏感。最常用的稳定性测试技术，包括在随机的数据集上，或者在每个独立的股票板块上测试来自不同周期、不同时段的数据。另外每个输入数据都应该对结果有显著作用。最简单的重要性，测试方法是去除一个输入变量，然后检查结果是否发生显著变化。如果每个输入变量都作用显著，那么我们对该信号会更有信心。\n第十九、Alpha研究中的算法和特殊技巧 有几个来自于工程学，如机器学习和数字信号处理的算法和技巧，可以用来提取有效的模式关系和特征，从而为生成阿尔法服务。\n在阿尔法研究中，我们频繁的处理弱的分离器和预测器。根据积极学习中的提升概念，可以在很多场合通过学习一个合适的权重函数，从而将若干弱学习者建立一个强学习者。\n阿尔法研究还需要与 时间序列数据打交道。来自数字信号处理的滤波概念可以有效地对于持续数据降噪，并将持续数据分解为趋势和周期分量。\n数字滤波是对原始时序数据进行数学运算，以稀释或放大信号的某个特性。 数字滤波最初和最重要的应用是平滑滤波，既对持续数据中的高平分量进行意志，最简单和最广为使用的数字绿波是简单移动平均滤波。然而，平滑滤波引入的时滞，而时滞在交易过程中则是极度不利于盈利的。因此可以使用一些替代性滤波技术，以最小时滞达到要求的批发等级。 数字滤波的另一个常见应用是将持续点分解为趋势和周期分量，趋势抽取设计对高频分量的抑制及低通滤波，而周期提取涉及对低频分量的抑制，即高通滤波。巴特沃斯于1930年提出的巴特沃斯滤波是一种常用和有效的低通绿波。高通滤波则可以通过从原始持续数据中减去低通滤波后的数据得到。同时，低通滤波和高通绿波可以串联起来，以选择或排斥原始持续数据中一个特定的频率波段。 阿尔法研究中的另一个有效技巧是特征提取。诸如主成分分析之类的算法可以帮助降低特征空间的维度。\n在阿尔法研究中应用PCA包括在高纬度数据中寻找模式、对观测数据进行聚类，采运在新矢量积下的投影之间的距离作为相似性的度量、主成分回归，以及收益率曲线分析。 第二十章、机构研究入门 本节介绍阿尔法研究人员为了创造新的交易灵感，是如何将机构研究资源转化为自己的开发工具的。\n获取新的市场策略，灵感可以有许多来源，包括与同学、同事或朋友的讨论，以及金融新闻、研讨会、书籍等。我们重点介绍可免费获得的金融市场相关学术论文。\n由于过去几十年，由各种专家公开发布的研究特别多，因而消化所有的文章或许不是获取灵感的最快办法。\n期刊： 正式的学术期刊是教授和专业研究人员发表研究成果的地方。正式期刊上的论文均经过了同行的严格评审，评审中的其他人员会对其进行点评。因此，在这个过程中幸存下来的研究论文通常没有严重的研究方法错误。你不仅可以从中获得交易想法，还可以获得新的研究方法的启发。 在这些出版物中讨论内容，通常是专家学者们认为在发表的当前时点上非常重要的主题。学术界的主要焦点不是寻求市场策略，而是要了解主导经济相互作用的根本力量。虽然两者息息相关，但并不是每一篇文章都会同时涉及前者。 具有更普适结论的论文通常发表在高影响因子的期刊上，而且这些论文也会受到学术界的更多关注。对于希望利用这些论文结论的市场策略开发者来说，这个特性有其优缺点。一方面，这表示，你将会有更多的工作要做，从对一般经济理论讨论到具体的战略。 期刊上的讨论可能与市场脱节，你需要将它与市场联系起来。另一方面，在这些讨论中，可能会有重要的经济基础理论，能够改进所构建的许多策略。同时的自己通过基础理论的启发设计新策略，而不是直接复制现有的结论，会使新策略有别于其他市场参与者。 与综合杂志相对的，还有聚焦在投资领域的杂志，其中的内容与投资策略和策略研究方法联系更紧密。在某些情况下，你甚至可能直接对其讨论的内容进行编辑和复制。但是这些策略被描述的非常详细，其他人也可以执行这些策略。不过，一旦你的核心策略代码通过测试，就可以考虑将其用作进一步创新的基础，这比从大致想法开始简单多了。 开源资料： 开源资料通常是可以自由访问的文档存储库，其中少部分允许用户自主的上传文档。自主上传意味着论文可能没有经过传统的同行评议过程。许多情况下，他们可能是正式学术论文的早期版本，以最终通过审查为目标。开源资料库有SSRN或 arXiv的论文库。一旦你确认了自己喜欢的学术作者名单，还可以在他们的个人页面上查看正在撰写的论文。开源系统的特点： 滞后性小、免费、品种更多、没有同行评议。 跟进讨论：公开分享研究成果的一个好处是会引发讨论。讨论对如何改进现有框架或了解大多数人对其优点和缺点的看法会非常有用。 以下是一些了解其他专业研究人员对你刚阅读的文章的看法：方法之一是关注一篇论文的引文。引文是会涉及你高阅读的论文的其他学术论文，通常会进行讨论改进、调整或批评。可以使用谷歌学术帮助获得跟踪引用。 学术研究的作者真的相信有效市场策略的存在吗？笔者认为学术研究人员非常重视EMH，不是因为这是一个可以和重力与运动定律一样坚不可摧的定律。相反，这是因为市场异常确实存在，但他需要一而再、再而三的仔细核实。一方面，由于各种历史、制度、法律、政治或经济原因造成的市场异常提供了获利的机会；另一方面，历史上有很多的投资者，将市场异常与风险因素混淆，并与因此付出了惨痛的代价。\n在金融报纸、会议、博客和数据库中，卖方分析师对企业和整个行业的研究都占有重要地位。在探究股价的大起大落时，分析师的荐股、调高评级、降低评级或修改目标价位被认为是主要原因的情况屡见不鲜。行业协会和学者间的大量研究发现，分析师研究中确实包含了大量重要信息。那么，一个对构建系统性市场策略有兴趣的研究员，为何要对测定公司级别的分析同样感兴趣呢？首先，有许多的研究是非常容易获取的。但是用户将无法通过公共资源获取所有的银行分析师公司研报，这是因为卖方分析师进行的是成本昂贵、过程复杂，并且耗时的分析，他们自然希望把分析先推荐给最有价值的客户。大部分分析师报告或市场评论专注于单一股票或行业，以下解释了为什么我们认为寻求系统性市场策略的研究人员可以从阅读股票分析报告中学习的原因：首先，比任何具体的买入或卖出推荐更重要的是分析师的思考过程。分析师作出判断，无论是何原因，一个有趣的问题是：我可以把它应用到其他公司吗？二，分析师通常在盈利电话会议期间提出非常好的问题。对于一位试图理解懈怠公司密集财务数据的新手研究员来说，这些问题可以帮上大忙。信息越多并不代表越好，特别是当每个公司都有二十多页财报的时候，试图把噪声和信号分开是个技术活。关注分析师聚焦的数据和趋势以及他们关注这些问题的目的，可以帮助我们了解关注哪些会计科目。我们关注的同样是其中是否具有普适性的逻辑，第三我们可以从股票分析师的工作中学习到很多方法论。例如不同行业的评估方法、每个行业可能都有自己独特的驱动力或衡量运营水平的指标，通常在分析报告中占据突出地位；分析师业报可以提供有效的交易信号。\n阅读分析师研报中的注意事项：正向偏见：学术研究人员认为，股票分析师作为一个群体可能会表现出正向偏见。比如说如果我们统计所有的分析师建议，可能就会发现，买入的建议比卖出的建议更多。羊群效应：羊群效应指分析师不希望其给出了公开建议和目标与市场上，其他分析师给出的太大不同。公开股票价格预测对分析师的职业发展有一定风险。在提他条件相同的情况下，跟随大多数人做出相同决定可能会更安全。同时更自信或生育更好的分析师，通常愿意做出与主流意见不同的决策建议。大多数的分析师可能有相同的信息来源，因此了解著名的分析时，为什么会得出与其他人不同的结论，他们的分析方法或数据来源有什么特殊性，如果可以，将其进行系统化，可能是一件很有趣的事。\n分析师的研究成果可以通过金融媒体获取； 分析师在达成他们最终建议的过程中使用的方法和推理可能是阿尔法研究人员的灵感来源之一； 分析师的建议目标价位可能会产生交易信号； 正向偏见和羊群效应是需要注意的两个要点。\n","id":0,"section":"posts","summary":"\u003ch2 id=\"一阿尔法信号构建要求\"\u003e一、阿尔法信号构建要求\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e基本特征\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e理论简洁且数学表达式简单\u003c/li\u003e\n\u003cli\u003e代码实现优雅\u003c/li\u003e\n\u003cli\u003e具有较高的夏普比率（风险调整后收益）\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e稳定性要求\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e对数据和参数微调不敏感\u003c/li\u003e\n\u003cli\u003e适用于多股票池、多区域市场\u003c/li\u003e\n\u003cli\u003e能够持续创造新高利润\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"二阿尔法开发流程\"\u003e二、阿尔法开发流程\u003c/h2\u003e\n\u003ch3 id=\"迭代循环框架\"\u003e迭代循环框架\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e数据变量挖掘\u003c/li\u003e\n\u003cli\u003e变量变化建模\u003c/li\u003e\n\u003cli\u003e构建持仓量数学表达式\u003c/li\u003e\n\u003cli\u003e历史回测验证\u003c/li\u003e\n\u003cli\u003e通过验证则纳入信号池\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"三阿尔法生命周期规律\"\u003e三、阿尔法生命周期规律\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e市场博弈机制\u003c/strong\u003e：盈利策略吸引资金→策略容量饱和→收益摊薄→策略失效→新机会产生\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e有效周期关键\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e历史验证时长\u003c/li\u003e\n\u003cli\u003e资金流入规模\u003c/li\u003e\n\u003cli\u003e市场结构变化速度\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e市场动态平衡\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e资金流动与策略有效性呈现周期性变化\u003c/li\u003e\n\u003cli\u003e新旧策略交替维持市场活力\u003c/li\u003e\n\u003cli\u003e阿尔法信号在市场演进中持续更新迭代\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"四阿尔法评估体系\"\u003e四、阿尔法评估体系\u003c/h2\u003e\n\u003ch3 id=\"核心评价指标\"\u003e核心评价指标\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e信息比率 = 每日损益均值 / 标准差\u003c/li\u003e\n\u003cli\u003e夏普比率（风险调整后收益）\u003c/li\u003e\n\u003cli\u003e最大回撤幅度\u003c/li\u003e\n\u003cli\u003e策略独特性（与其他信号相关性\u0026lt;0.5）\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"回测验证要点\"\u003e回测验证要点\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e样本外测试有效性高 and 样本内表现好\u003c/li\u003e\n\u003cli\u003e极端值对模型的破坏性检验\u003c/li\u003e\n\u003cli\u003e交易成本敏感性测试\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"五历史市场认知误区\"\u003e五、历史市场认知误区\u003c/h2\u003e\n\u003ch3 id=\"核心观点\"\u003e核心观点\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e历史市场并非更易交易\u003c/li\u003e\n\u003cli\u003e过去赚钱同样具有挑战\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e现在去看历史，会觉得当时的市场比现在更加容易交易，这是因为如下几个原因第一，你当时不会有现在的领悟，第二你现在拥有之前无法得到的数据，第三，你当时没有现在这么强大的计算能力和技术，因此每个十年都有他自己的市场和独特的市场机会，这取决于阿尔法开发者是否能够有当时的技术数据寻找的市场机会。反观历史，诸如过去预测市场和赚钱更容易这样的想法是错误的。\u003c/p\u003e","tags":["Quant Knowledge","readings"],"title":"《寻找阿尔法——量化交易策略》读书笔记整理","uri":"https://zhoujb22.github.io/2025/01/%E5%AF%BB%E6%89%BE%E9%98%BF%E5%B0%94%E6%B3%95%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E7%AD%96%E7%95%A5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86/","year":"2025"},{"content":"Overview Overview 主要介绍量化交易员形成 alpha models 的想法的来源，实施的过程，以及最终形成的量化交易系统的组成成分。Overview 同时也强调了量化交易中‘人’的重要性，以及我们并不应该只关注量化系统中的 alpha models 。 Quants are perhaps not so mysterious as is generally supposed. They tend to start with ideas that any reasonable observer of the markets might also have, but rather than using anecdotal, experiential evidence\u0026ndash;or worse, simply assuming that their ideas are true\u0026ndash;quants use market data to feed a research process to determine whether their ideas in fact hold true over time. Once quants have arrived at a satisfactory strategy, they build their strategy into a quant system. These systems take the emotion out of investing and instead impose a disciplined implementation of the idea that was tested. But this should not be read minimizing the importance of human beings in the quant trading process. Quants come up with ideas, test strategies, and decide which one to use, what kinds of instruments to trade, at what speed and so on. Humans also tend to control a \u0026ldquo;panic button, \u0026quot; which allows them to reduce risk if they determine that markets are behaving in some way that is outside the scope of their models\u0026rsquo; capabilities.\nQuant strategies are widely ignored by investors as being opaque and incomprehensible. Even those who do focus on this niche tend to spend most of their time understanding the core of the strategy, its alpha model. But we contend that there are many other parts of the quant trading process that deserve to be understood and evaluated. Transaction cost models help determine the correct turnover rate for a strategy, and risk models help keep the strategy from betting on the wrong exposures. Portfolio construction models balance the conflicting desires to generate returns, expend the right amount on transaction costs, manage risk, and deliver a target portfolio to execution models, which implement the portfolio models, which implement the portfolio models, which implement the portfolio model\u0026rsquo;s decisions. All this activity is fed by data and driven by research. From afar, we have begun to shed light on the black box. Alpha Model: How Quants Make Money 正式开始介绍 Alpha Models, 给出了具有哲理意义的 Alpha Models 的定义，同时也强调获得超额收益的同时，必须也要承担可接受范围内的风险。 Alpha, generally is used as a way to quantify the skill of an investor or the return she delivers independently of the moves in the broader market. The portion of the return that can be attributed to market factors is then referred to as beta. Our definition of alpha\u0026ndash;which I stress is not conventional\u0026ndash;==is skill in timing the selection and/or sizing of portfolio holdings==. A pursuit of alpha holds as a core premise that no instrument is inherently good or bad, and therefore no instrument is worth always owning or perpetually shorting. In the case of alpha models: ==Whatever exposures they take on are rewarding if they are in favor, and are costly if they are out of favor.==\nTheory-Driven Alpha Models \u0026ndash; Majority 大多数的量化从业者都试图以理论来解释市场现象，并希望从中获得收益。本段介绍了理论驱动模型的形成过程、部分常见的关于量化行业的误解以及如何对理论驱动模型进行分类。 Theoretical scientists try to make sense of the world around them by hypothesizing why it is the way it is. Start with the observations of the market, then think of generalized theory that could explain the observed behavior -\u0026gt; rigorously test it with market data to see if it is untrue or supported. Many quants think that their theories are somewhat unique to them, which is part of the reason so many of them are so secretive. But this turns out, almost always, to be a delusion. Meanwhile, many outside of the quant trading world believe that the kinds of strategies quants use are complex and based on complicated mathematical formulae. This generally also turns out to be false.(Zhou: Form my own quant internship experience, most of time under a medium or high frequency, it\u0026rsquo;s true. At least the maths used in the alpha models construction is intelligible if you spend enough time thinking about. I believe that part of the reason can be a complex mathematical model is hard to compute in limited time)\nMost of what theory-driven quants do can be relatively easily fit into one of six classes of phenomena: trend, reversion, technical sentiment, value/yield, growth, and quality. (Actually the same as those that can be utilized by discretionary traders seeking alpha) These six categories can be further understood by examining the data that they use: price-related data and fundament data.\n接下来我们将按照数据类型，对六类 alpha model 进行介绍。 Strategies Utilizing Price-Related Data Trend-Following or Momentum 趋势跟随或动量的alpha模型是一种利用市场动量的投资模型，通过分析资产的价格走势和动量来预测并捕捉超额收益的机会。本节介绍了趋势形成的原因、量化交易者如何识别动量。 Based on: Markets sometimes move for long enough in a given direction that one can identify this trend and ride it.\nWhy trends happening:\nFor US economy and market, imagine that the bears have it right. The earliest adopters of the idea place their trades in accordance with it by, for example, selling bonds short. As more and more data come out to support their thesis and as a growing mass of market participants adopts the same thesis, the price of U.S. bonds may take a considerable amount of time to move to its new equilibrium, and this slow migration from one equilibrium to the next if the core opportunity that the trend follower looks to capture. Greater fools theory. Because people believe trends, they tend to act follow the trends in their mind, which itself perpetuates the trend. Lots of evidence in markets seems a valid enough reason to believe in trends. How to use trend:\nLooking for a \u0026ldquo;significant\u0026rdquo; move in a given direction in an instrument. (They bet it a likely sign of a growing consensus) We get many ways to define what kind of move is significant. The most common terms used to describe this type of action is \u0026ldquo;filtering\u0026rdquo; and \u0026ldquo;conditioning\u0026rdquo;. This turned out to be an important source of differentiation among the various trend-following players. Counter-Trend or mean reversion 本节介绍均值回归策略形成的原因、均值回归策略承担的风险、均值回归策略不与趋势跟踪策略的矛盾的原因。 Based on: There exist s a center of gravity around which prices fluctuate, and it is possible to identify both this center of gravity and what fluctuation is sufficient to warrant making a trade.\nWhy reversion happening:\nSometimes there are imbalances among buyers and sellers, i.e. overbuy and oversell. The price moves abruptly, which increase the probability that the price will reverse again at some point. Participants are not all aware of each other\u0026rsquo;s views and actions, and as they each place orders that drive a price to its new equilibrium level, the price can overshoot due to excess supply or demand at any given time. Risks:\nLiquidity provider. Betting against momentum. Bearing the risk of adverse selection. Interestingly, trend and mean reversion strategies are not necessarily at odds with each other:\nLonger-term trends can occur, even as smaller oscillations around these trends occur in the shorter term. In fact, some quants use both of these strategies in conjunction. Mean reversion strategies focus on the current mean of equilibrium and then must determine what amount of divergence from that equilibrium is sufficient to warrant a trade. Different timeframes. Trends -\u0026gt; Longer time horizons; Mean Reversion -\u0026gt; Shorter time horizons. The two types of strategies are likely to work well in different regimes. Examples: Statistical Arbitrage(stat arb, for short): it bets on the convergence of the prices of similar stocks whose prices have diverged.\nTechnical Sentiment 技术情绪需要利用价格相关的数据得到，本节展示了技术情绪的含义以及目前的应用案例。 Based on: An interesting third class of price-related strategies tracks investor sentiment\u0026ndash;expressed through price, volume, and volatility behaviors. No clear economic rationale that gives birth to a strategy. Given a high degree of positive sentiment in some instrument would indicate that:\nOverbought Will move higher Used as a conditioning variable(the most common, for example, ignore the low-volume trend) Examples:\nLook at the options markets to determine sentiment on the underlying. The volume of puts and calls as an indicator of sentiment. The implied volatilities of put versus calls.(==puts tend to have higher volatilities==) Technical sentiment strategy analyzes trading volume, open interest(未平仓合约), or other related type of inputs as an indicator of future prices. Higher-frequency traders evaluate the shape of the limit order book to determine near-term sentiment. Strategies Utilizing Fundamental Data 使用基本面数据的策略主要可以分为三类，Fama-French的发现极大地帮助了量化行业应用基本面数据到实际投资中。 Three groups: value/yield, growth or quality Fama-French: \u0026ldquo;The Cross Section of Expected Stock Returns\u0026rdquo; advanced the field dramatically. They found that stocks\u0026rsquo; betas to the market are not sufficient enough to explain the differences in the returns of various stock. Rather, combining betas with historical data about the book-to-price ratio and the market capitalization of the stocks was a better determinant of future returns. (Something ironic: The entire domain of quantitative alpha trading owes so much to Eugene Fama, because Fama\u0026rsquo;s most famous work advanced the idea that markets are efficient.)\nValue/Yield 本节介绍了instrument的价值指标，量化从业者需要转换一些常见的价值指标数据，使之具备更加良好的性质；同时本节更深入地讲解了为什么如 Earning Yield 的价值指标在投资中有意义，列举了一些实际中的应用场景。 Many metrics to describe value in various asset classes, but most of them ends up being ratios of some fundamental factor versus the price of the instrument, such as P/E ratio. Quants tend to invert such ratios, keeping price in the denominator, known as earning yield.(Zhou: The curve could be smoother as the earnings fluctuate.)\nQuants should transform many fundamental quantities into more usable, well-behaved variables that can lend themselves more readily to systematic trading application.\nMost often, value is thought of as a strategy that is defined by buying cheap. But it can be too swallow for a definition. In reality, the markets tend to overestimate the risk in risky instruments and possibly to underestimate the risk in less risky ones. Therefore, it can pay off to own the more risky asset and sell the less risky asset. It means that sometimes instruments have a higher yield than is justified by their fundamentals dimply because the market is requiring a high yield for that kind of instrument at the moment. An investor who can purchase this instrument while it has a high yield can profit from the movement over time to a more efficient, fair price. In reality, prices are more often the determinant of value than changing fundamentals, this means that the instrument\u0026rsquo;s price must have fallen substantially. So in some sense, ==the value investor is being paid to take on eht risk of standing in the way of momentum==.\nExplaination：sometimes, an asset's price drops too much because people demand a high return for taking on that \u0026quot;risky\u0026quot; investment. If you, as an investor, buy it while it's cheap, you might profit when the market later realizes it overestimated the risk and corrects the price to a fairer level. Examples:\nCarry trade: Buying the undervalued security and selling the overvalued one against. One receives a higher yield from the long position and finances this with the short position, on which a lower yield must be paid. The spread between the yield received and the yield paid is the carry. If nothing else happens, a carry trade offers an investor a baseline of rate of return. Carry trading is an enormously popular kind of strategy for quants(and discretionary traders) in currencies. In equities, many kind of traders seek to define metrics of \u0026lsquo;cheapness,\u0026rsquo; such as earning before interest, taxes, depreciation, and amortization(EBITDA) versus enterprise value(EV) or book value to price. In the case of most commodities, value is usually thought of more to a \u0026ldquo;cheap/expensive\u0026rdquo; analysis, via concepts of the expected supplies of a commodity versus the expected demand for that commodity, rather than being focus on yield. Growth/Sentiment 本节介绍了根据证券背后标的的成长潜力来判断证券价格走势的策略，具体分为根据基本面数据和根据分析师态度两大类型。 Based on: the asset in question\u0026rsquo;s expected or historically observed level of economic growth. All else being equal, it is better to buy assets that are experiencing rapid economic growth and/or to sell assets that experiencing slower negative growth.\nGrowth metrics:\nprice/earnings-to-growth ratio(PEG) ratio (PE ratio vs. EPS growth ratio): Trader compare growth expectations and value expectations to see whether a given instrument is fairly pricing in the positive or negative growth that the trader believes the asset will likely experience. 解释：如果对企业股票的定价已经精确考虑到了企业的发展预期，那么对于量化交易者，这家企业的股票就不再存在盈利的空间。 The justification for growth investing is that growth if typically experienced in a trending manner, and the strongest growers are typically becoming more dominant relative to their competitors. So growth investors try to be early in the process of identifying growth and hence, early in capturing the implied increase in the future stature of a company.\nAt the macro level, some foreign exchange trading concepts are predicated on the idea that it is good to be long currencies of countries that are experiencing relatively strong growth, because it is likely that these will have higher relative interest rates in the future than weaker-growth or recession economies, which makes this a sort of forward-looking carry trade. An important variant of growth trading utilized by a wide variety of quants focuses on analysts\u0026rsquo; earning estimate revisions. This idea is to try to get an early glimpse of a company\u0026rsquo;s growth by using the analyst\u0026rsquo;s expectations rather than simply waiting for the company itself to report its official earnings results. It is called a sentiment-based strategy.\nAccording to the author\u0026rsquo;s experience, these two types of growth strategies are highly enough correlated in practice to warrant their being treated as close cousins.\nQuality 本节介绍质量指标，详细介绍了一般从五个方面评价 instrument 的质量，同时质量指标在特定时空下能产生好的收益。 Based on: It is better to own instruments that are of high quality and better to sell or be short instruments of poor quality. Capital safety is important, and neither growth nor value strategies really capture this concept. It is particularly important in a stressful market environment(fight-to-quality environment).\nThe five categories that quality signals fall into:\nLeverage: short higher-levered companies and go long short less-levered companies, all else equal. Such as debt-to-equity ratios of stocks. Diversity of revenue: All else equal, a company that makes money doing a wide variety of things for a variety of customers should be more stable than a company that makes exactly one kind of widget for some narrow purpose. Such as volatility of revenues. Management quality: Buy companies or countries that are led by better teams. Fraud risk: Buy companies or countries where the risk of fraud is low. Such as earning quality signal, which attempts to measure how close are a company\u0026rsquo;s true economic earnings to reported earnings-per-share numbers. Sentiment that investors have regarding the quality of the issuer of an instrument(company or country): Quality-related sentiment strategies are focused on a forward-looking assessment of the four quality categories above. Quality\u0026rsquo;s performance over time fluctuates greatly and is highly dependent on the market environment. In 2008, quality was a particularly successful factor in predicting the relative prices of banking stocks.\n","id":1,"section":"posts","summary":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-zhou\"\u003eOverview 主要介绍量化交易员形成 alpha models 的想法的来源，实施的过程，以及最终形成的量化交易系统的组成成分。Overview 同时也强调了量化交易中‘人’的重要性，以及我们并不应该只关注量化系统中的 alpha models 。\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eQuants are perhaps not so mysterious as is generally supposed. They tend to start with ideas that any reasonable observer of the markets might also have, but rather than using anecdotal, experiential evidence\u0026ndash;or worse, simply assuming that their ideas are true\u0026ndash;quants use market data to feed a research process to determine whether their ideas in fact hold true over time. Once quants have arrived at a satisfactory strategy, they build their strategy into a quant system. These systems take the emotion out of investing and instead impose a disciplined implementation of the idea that was tested. But this should not be read minimizing the importance of human beings in the quant trading process. Quants come up with ideas, test strategies, and decide which one to use, what kinds of instruments to trade, at what speed and so on. Humans also tend to control a \u0026ldquo;panic button, \u0026quot; which allows them to reduce risk if they determine that markets are behaving in some way that is outside the scope of their models\u0026rsquo; capabilities.\u003c/p\u003e","tags":["Quant Knowledge","Readings"],"title":"The Black Box -- Reading Notes","uri":"https://zhoujb22.github.io/2024/11/the-black-box--overview-and-theory-driven-alpha-models/","year":"2024"},{"content":"前言 上一节中，我们使用Dijkstra算法来获取最小生成树中，计算某个节点到其他所有节点的最短距离和。值得注意的是，我们必须先使用第一节中的prim算法或者其他近似的算法才能来进一步应用Dijkstra算法计算距离和。即我们不能直接使用edge中所有节点之间的距离构造的包含非树边的图去应用Dijkstra算法。\n我们用下面这幅最小生成树图进行Dijkstra算法的推演：\n包含非树边的图应用Dijkstra算法计算距离和 此处“包含非树边的图”指代上图中绿色与黑色线条权重同时存在的情况。\n选取起始点D，Dijkstra算法第一步会更新D距离A/B/E/F点的距离到distances字典当中。 接下来推出与D最近的点A，遍历A的邻居：首先排除回到D的可能；对于A的邻居B，距离为7，distance = current_distance + neighbor_distance = 5 + 7，由于12\u0026gt;9，所以distance字典中的值不会被更新； …… 可以发现，如果包含非树边，Dijkstra 算法并没有严格沿着最小生成树路径走，而是选择了不属于最小生成树的路径。直接使用包含所有节点对间距离的完整图作为输入，Dijkstra 算法会尝试找到所有最短路径，但不保证路径仅沿最小生成树。因此，需先生成最小生成树或移除非树边，才能确保计算的路径和基于最小生成树。\n小结：Dijkstra 算法属于单源路径搜索（Single-Source Shortest Path, SSSP），指的是从一个指定的起点节点（称为“源节点”）出发，计算到图中其他所有节点的最短路径的过程。Dijkstra 算法专门用于在权重非负的有向图或无向图中，计算从源节点到所有可达节点的最短路径。\n关于本节 最小生成树已经确保了所有节点之间的连接路径权重最小，且没有任何冗余边，因此在最小生成树上从任意节点出发到其他节点的最短路径就是其唯一的路径。\n本节当中，我们会引入一种在最小生成树图背景下，相比Dijkstra 算法更高效的算法，广度优先搜索BFS的变种算法。\nBFS from collections import defaultdict, deque import random def calculate_distances_from_node(adjacency_list, start_node): \u0026quot;\u0026quot;\u0026quot; 计算从选定节点到所有其他节点的最短路径和 :param adjacency_list: 邻接表 :param start_node: 选定的节点 :return: 从该节点到所有节点的距离总和 \u0026quot;\u0026quot;\u0026quot; total_distance = 0 visited = set() queue = deque([(start_node, 0)]) # 队列存储 (当前节点, 到该节点的距离) while queue: current_node, current_distance = queue.popleft() if current_node not in visited: visited.add(current_node) total_distance += current_distance # 遍历相邻节点 for neighbor, weight in adjacency_list[current_node]: if neighbor not in visited: queue.append((neighbor, current_distance + weight)) return total_distance # 计算从选定节点到所有节点的最短距离和 shortest_path_sum = calculate_distances_from_node(adjacency_list, selected_node) print(f\u0026quot;随机选定节点: {selected_node}\u0026quot;) print(f\u0026quot;从该节点到所有节点的最短距离和: {shortest_path_sum}\u0026quot;) 分析 calculate_distances_from_node 的步骤 初始化：初始化 total_distance 为0，并创建一个集合 visited 来记录已访问的节点。用双端队列 queue 存储起始节点和初始距离（0）。\n广度优先遍历：每次从 queue 中取出一个节点 current_node，若该节点未访问，则标记为已访问并将 current_distance 加入 total_distance。\n更新相邻节点：遍历当前节点 current_node 的所有邻接节点 neighbor，若邻接节点未访问，则将其加入 queue，并累加距离 weight。\n结果：最终返回从 start_node 到所有节点的距离和 total_distance。\n特点 广度优先搜索（BFS）是一种层次遍历算法，它按照层次逐层访问图中的节点。这意味着 BFS 首先访问起始节点，然后访问所有与起始节点相邻的节点，再访问这些邻居的邻居，以此类推。该方法没有使用优先队列，所以距离更新不是按照最小路径进行扩展。 遍历方式类似于广度优先搜索，但在带权重的图上，该方法未必能找到真实的最短路径和，仅适用于无权图或权重较小且结构较简单的图。 若图有负权边或不规则权重分布，BFS 会计算非最优路径和，因此该算法适用范围有限。 Dijkstra与BFS比较 函数 使用算法 适用图类型 是否找到最短路径和 时间复杂度 dijkstra Dijkstra 算法 任意带非负权边的图 是 $(O((V + E) \\log V))$ calculate_distances_from_node 广度优先搜索（变种） 无权图或简单权重图 不一定 $(O(V + E))$ 适用范围 Dijkstra 算法（dijkstra 函数）适用于带权边，能找到最短路径和，推荐用于一般的最短路径问题。 广度优先搜索法（calculate_distances_from_node 函数）更适合无权图。对于加权图，这种方法不保证找到最短路径和。 算法复杂度分析 Dijkstra 算法：\nDijkstra 算法在普通图中的时间复杂度为 $(O(E \\log V))$，其中 E 是边数，V 是节点数。 Dijkstra 使用优先队列来获取当前最短距离节点，适合有权图的最短路径计算。 在最小生成树中，虽然边数减少为 (V - 1)，但它仍然需要管理优先队列来获取最短路径，导致一定的额外操作。 BFS 方式 (calculate_distances_from_node)：\n在无环的树结构中，BFS 的时间复杂度为 $(O(V + E))$。 对于最小生成树来说，边数是 (V - 1)，所以其复杂度约为 (O(V))。 由于最小生成树中每两个节点间有唯一路径，BFS 不需要更新距离，直接沿路径遍历即可获得最短路径。 效率对比 优先队列管理开销：Dijkstra 需要维护一个优先队列，即使在最小生成树这种特殊结构中也要通过堆操作来管理节点距离。而 calculate_distances_from_node 仅需简单的队列，开销更低。 适用性：在无环的树结构中，BFS 能简单快速地遍历所有节点，因此在最小生成树上 calculate_distances_from_node 更适合，速度更快。 总结 在最小生成树这个特殊的情境下，我们已经有了最小权重形成的树，因此使用BFS进行一层一层的距离计算，最终会得到节点距离其他所有的节点的最小的距离和。此时calculate_distances_from_node 会比 Dijkstra 算法更高效，因为 BFS 的复杂度较低且无额外的优先队列开销，因此能更快计算出从起点到所有节点的最短路径和。\n","id":2,"section":"posts","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e上一节中，我们使用\u003ccode\u003eDijkstra\u003c/code\u003e算法来获取最小生成树中，计算某个节点到其他所有节点的最短距离和。值得注意的是，我们必须先使用第一节中的\u003ccode\u003eprim\u003c/code\u003e算法或者其他近似的算法才能来进一步应用\u003ccode\u003eDijkstra\u003c/code\u003e算法计算距离和。即我们不能直接使用\u003ccode\u003eedge\u003c/code\u003e中所有节点之间的距离构造的包含非树边的图去应用\u003ccode\u003eDijkstra\u003c/code\u003e算法。\u003c/p\u003e","tags":["Quant Knowledge","Algorithms"],"title":"Minimum spanning tree 3","uri":"https://zhoujb22.github.io/2024/10/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E5%8E%9F%E7%90%86%E4%B8%8E%E7%AE%97%E6%B3%95-3/","year":"2024"},{"content":"引言 前一部分中，我们了解到了可以使用prim来构建最小生成树，为了刻画节点在整个树中是否处于中心位置，有许多衡量这一位置的指标，但本文中我们可以采用测量某一节点到所有其他节点的沿最小生成树路径的总距离。本文引入算法来实现高效计算这一距离（实际上是接近中心度的中间过程）。\n1、度中心度 节点度中心度，计算方法为节点的连接的边的数量除以可能的最大连接数，对于 n 个节点的网络，最大连接数为 n-1，即：\n$$𝑑_𝑣 = deg(v)⁄𝑚$$\n其中 deg 为节点 v 的连接边数量，m 为最大连接数（n-1）。\n2、接近中心度 接近中心度衡量了节点与其他节点的距离，计算方法为加总节点到其他所有节点的最短距离，接近中心度也通过最大连接距离进行归一化，即：\n$$𝑐_𝑣 = （n − 1)⁄𝑑$$\n其中 d 为节点与其他节点连接距离的加总。\n3、中介中心度 中介中心度衡量了，节点位于其他节点的最短路径上的程度，即：\n$$b_v = \\sum_{s,t} \\frac{\\sigma(s,t|v)}{\\sigma(s,t)}$$\n𝜎(𝑠,𝑡)为节点 s，t 的最短路径的数量，𝜎(𝑠,𝑡|𝑣)为 s 和 t 最短路径经过节点 v 的数量。\n\u0026ndash;来源：《股票网络中心度因子异象研究\u0026ndash;by华创证券》\n示例：\n假设存在最小生成树: (7, \u0026lsquo;A\u0026rsquo;, \u0026lsquo;B\u0026rsquo;)，(5, \u0026lsquo;A\u0026rsquo;, \u0026lsquo;D\u0026rsquo;)， (8, \u0026lsquo;A\u0026rsquo;, \u0026lsquo;C\u0026rsquo;) 对于A，距离和为7+5+8=20; 对于B，距离和为B到A、C、D的距离和，为7+(7+5)+(7+8)=34; 对于C，距离和为C到A、B、D的距离和，为8+(8+5)+(8+7)=36； 观察可以发现，在该树中，A处于中心位置，其到所有其他节点的沿最小生成树路径的总距离最小，而边缘位置的节点，该数值越大；想象节点为单支股票，衡量股票是否处于同类股票的中心位置，有助于确定股票在同一行业中的“重要程度”。\n为Dijkstra算法构建graph # 构建图的邻接表 def build_graph(result): graph = defaultdict(list) for distance, node1, node2 in result: graph[node1].append((distance, node2)) graph[node2].append((distance, node1)) return graph Dijkstra算法: 计算某个节点到其他所有节点的最短距离和 # Dijkstra算法,计算某个节点到其他所有节点的最短距离和 def dijkstra(graph, start): # 初始化距离字典 distances = {node: float(\u0026quot;inf\u0026quot;) for node in graph} distances[start] = 0 priority_queue = [(0, start)] while priority_queue: current_distance, current_node = heapq.heappop(priority_queue) # 如果从队列取出的距离大于当前节点已知的最短距离,则跳过 if current_distance \u0026gt; distances[current_node]: continue # 更新相邻节点的最短距离 for neighbor_distance, neighbor in graph[current_node]: distance = current_distance + neighbor_distance if distance \u0026lt; distances[neighbor]: distances[neighbor] = distance heapq.heappush(priority_queue, (distance, neighbor)) # 返回从起点到所有其他节点的距离和 return sum(distances.values()) 注：\n在 Python 中，当你对字典（dict）直接使用 for 循环时，for node in graph 会遍历字典的键（keys）。换句话说，node 代表的是字典中每个键的值，而不是字典的值（values）。 在 Python 中，空列表 [] 被视为 False。在循环条件中，只有当条件为 True 时，循环才会执行。 算法原理 Dijkstra算法，用于计算从起点 start 到图 graph 中所有其他节点的最短路径。具体工作流程如下：\n初始化:\n定义一个字典 distances 来存储从起点 start 到每个节点的最短距离。初始化时，起点到自己的距离为 0，其余所有节点的距离设为无穷大（float(\u0026quot;inf\u0026quot;)）。 使用优先队列 priority_queue（小顶堆），将起点 start 放入队列，优先级为 0，表示当前已知的距离。 处理队列中的节点：\n第一轮，通过 heapq.heappop 从优先队列中取出具有最小距离的节点 current_node 和对应的距离 current_distance。此时取出来的节点是start，由于0=0，所以不跳过下一回合； 对于graph中start的节点，遍历与start有距离数据的节点，这些新节点与start的距离是0+neighbor_distance，由于distances[neighbor]在第一轮必定是无穷大的，更新该节点在distance字典中的值，并将(distance, neighbor)压入最小堆priority_queue中。 后续循环过程中，由于if distance \u0026lt; distances[neighbor]使得新节点的搜寻不能走回头路，因为distance = current_distance + neighbor_distance使得如果走回头路，distance一定会大于在distances中储存的上一轮的数据。 重复步骤：\n继续从优先队列中取出下一个距离最小的节点，更新其邻居的最短距离，直到优先队列为空。 返回结果：\n最终，算法返回从起点到所有其他节点的最短路径和 sum(distances.values())。 时间复杂度 该算法使用优先队列来选择最小距离的节点，单次操作的时间复杂度为 ( O(\\log V) )，其中 ( V ) 是节点的数量。对于每条边的松弛操作，时间复杂度是 ( O(E) )，因此总的时间复杂度为 ( O((V + E) \\log V) )。 适用场景 Dijkstra 算法通常用于加权图中找出单源最短路径，图的边权重必须为非负数。 并行执行算法 # 计算每个节点的最短距离和,支持并行化 def compute_all_shortest_path_sums(graph, n_jobs=4): node_sums = Parallel(n_jobs=n_jobs)(delayed(dijkstra)(graph, node) for node in graph) # 构建字典,将结果和节点对应起来 return {node: node_sum for node, node_sum in zip(graph, node_sums)} 并行操作的理解： Parallel 的性质：\nParallel 是 joblib 库中的并行执行器，确保了任务的结果顺序与输入顺序相同，即使任务是并行执行的。在任务分配给多个工作线程后，Parallel 会根据输入顺序收集这些任务的输出结果，然后按照这个顺序将结果返回。\n因此使用zip(graph, node_sums)不会影响key与距离的匹配。\n换句话说，不管某个任务完成得早还是晚，Parallel 都会按提交任务时的顺序对输出结果进行排序。\ndelayed 的作用：\ndelayed 只是用来延迟计算的包装器，主要是将函数调用（如 dijkstra(graph, node)） 转换为一个可传递给并行执行的任务对象。它的作用是封装这些函数以便传递给 Parallel。\n然而，delayed 并不会决定任务返回结果的顺序，结果顺序的维护完全是 Parallel 内部实现的。\n","id":3,"section":"posts","summary":"\u003ch2 id=\"引言\"\u003e引言\u003c/h2\u003e\n\u003cp\u003e前一部分中，我们了解到了可以使用prim来构建最小生成树，为了刻画节点在整个树中是否处于中心位置，有许多衡量这一位置的指标，但本文中我们可以采用测量某一节点到所有其他节点的沿最小生成树路径的总距离。本文引入算法来实现高效计算这一距离（实际上是接近中心度的中间过程）。\u003c/p\u003e","tags":["Quant Knowledge","Algorithms"],"title":"Minimum spanning tree 2","uri":"https://zhoujb22.github.io/2024/10/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E5%8E%9F%E7%90%86%E4%B8%8E%E7%AE%97%E6%B3%95-2/","year":"2024"},{"content":"常见的基于股价变化构建网络的方式 Mantegna 最早将复杂网络研究方法引入股票市场，Barabasi 在 2003 年的研究中证实美国股票市场满足无标度网络性质。在国内股票市场的研究中，Huang 在 2009 年的研究中证实沪深 1080 只股票满足幂律分布，Mai 在 2014年的复杂网络系统研究表明沪深 300 的核心行业为工业，谢凌峰和陈志 2016 年的研究中表明在沪港通开通后网络的平均度和聚类系数都有了显著的上升。\n在上述的研究中，构建网络的方法大致可以分为三类，第一类是类似牛晓健（2021）的做法，采用阈值截断法(Threshold Truncation Method，TTM)构建网络；第二类是类似于Huang（2009）的做法，采用平面最大过滤图法(Planar Maximally Filtered Graph，PMFG)构建网络；第三类是类似于谢赤（2021）的做法利用最小生成树(Minimum Spanning Tree，MST)法构建网络。\n最小生成树法对网络信息的过滤最为严格，只提取网络中各节点间相关性最大的主要信息；平面最大过滤图方法最大限度上保留了网络中与有效信息相关的连边，但有效信息分析相对复杂、网络计算速度相对较慢；阈值截断法基于不同阈值构建的网络结构差异较大。\n\u0026ndash;来源：《股票网络中心度因子异象研究\u0026ndash;by华创证券》\n通过prim算法构建最小生成树 from collections import defaultdict from heapq import * def prim(start, edges): \u0026quot;\u0026quot;\u0026quot; 用于根据所有节点之间的距离,然后生成最小生成树 :param start: 初始节点选择；此节点可以随机化，但将导致多次使用函数结果不唯一； :param edges: 股票列表产生的距离数据，形式为(7, 'A', 'B')，tuple的第一个元素表示距离，第二、三个元素表示节点的名称，此处要求不能同时存在(7, 'A', 'B')与(7, 'B', 'A')。 :return: 构建最小生成树的距离数据 \u0026quot;\u0026quot;\u0026quot; adjacent_dict = defaultdict(list) # 注意:defaultdict(list)必须以list做为变量 # 将(7, 'A', 'B')分别在A/B的key对应值的list中记录，保持新增元组的第二个元素与key相同。 for weight, v1, v2 in edges: adjacent_dict[v1].append((weight, v1, v2)) adjacent_dict[v2].append((weight, v2, v1)) \u0026quot;\u0026quot;\u0026quot; 经过上述操作,将图转化为以下邻接表形式: {'A': [(7, 'A', 'B'), (5, 'A', 'D')], 'C': [(8, 'C', 'B'), (5, 'C', 'E')], 'B': [(7, 'B', 'A'), (8, 'B', 'C'), (9, 'B', 'D'), (7, 'B', 'E')], 'E': [(7, 'E', 'B'), (5, 'E', 'C'), (15, 'E', 'D'), (8, 'E', 'F'), (9, 'E', 'G')], 'D': [(5, 'D', 'A'), (9, 'D', 'B'), (15, 'D', 'E'), (6, 'D', 'F')], 'G': [(9, 'G', 'E'), (11, 'G', 'F')], 'F': [(6, 'F', 'D'), (8, 'F', 'E'), (11, 'F', 'G')]}) \u0026quot;\u0026quot;\u0026quot; minu_tree = [] # 存储最小生成树结果 visited = {start} # 存储访问过的顶点,注意指定起始点 adjacent_vertexs_edges = adjacent_dict[start] heapify(adjacent_vertexs_edges) # 转化为小顶堆,便于找到权重最小的边 while adjacent_vertexs_edges: weight, v1, v2 = heappop(adjacent_vertexs_edges) # 权重最小的边,并同时从堆中删除. if v2 not in visited: visited.add(v2) # 在used中有第一选定的点'A',上面得到了距离A点最近的点'D',举例是5.将'd'追加到used中 minu_tree.append((weight, v1, v2)) # 再找与d相邻的点,如果没有在heap中,则应用heappush压入堆内,以加入排序行列 for next_edge in adjacent_dict[v2]: # 找到v2相邻的边 if next_edge[2] not in visited: # 如果v2还未被访问过,就加入堆中 heappush(adjacent_vertexs_edges, next_edge) return minu_tree prim代码解读 defaultdict:用以指定字典的value类型。prim函数中默认adjacent_dict为以list为元素的字典。在请求的key未找到时，会将新的key默认为指定的类型。prim函数中，默认指定该类型为一个空的list。这也是可以直接对value使用append method的方法。 示例：源自官方文档：Setting the default_factory to int makes the defaultdict useful for counting (like a bag or multiset in other languages): s = 'mississippi' d = defaultdict(int) for k in s: d[k] += 1 sorted(d.items()) heapq: 该模块提供了堆队列算法（也称为优先级队列算法）的实现。堆是二叉树，每个父节点的值都小于或等于其子节点的值。 堆的一个有趣特性是其最小元素始终是根。堆排序可以通过将所有值推送到堆上然后一次弹出一个最小的值来实现。 heapq中，==堆元素可以是元组。==这对于在跟踪的主记录旁边分配比较值（例如任务优先级）很有用。 prim使用heapq的原理： 选定start后，将与start存在距离的点压入小栈堆。 找到小栈堆内距离最小的组，如果与start对应的新节点没有被访问过，就标记新节点为visited，同时将这组最小距离组合放入mini_tree。 将2中相邻节点（未被标记为visited）都压入小栈堆。 此时小栈堆中有与start和2中新节点所有相邻的节点。 循环，回到1，重复上述流程，通过小栈堆找到与start或2中新节点距离最近的点，直至adjacent_vertexs_edges没有元素而停止。 堆的有趣类比： 参考锦标赛制，倘若平铺所有list中的元素，如[1, 3, 2, 6, 8, 5]，每两数选出最小数晋级，上浮结果为[1, 2, 5]；再一轮上浮结果为[1, 5]；最后一轮上浮结果为[1]。可以发现list中最小的元素始终在堆顶。 prim使用heapq的优势在于，小堆栈使得每一轮使用尽可能少的时间便能选择出距离最小的元组，让最小生成树生成的过程加速。 好的，插入新元素后，堆的“上浮”操作是为了保持堆的性质。我们以一个最小堆（min-heap）为例，来演示插入新元素后进行上浮的过程。\nheappush原理演示 [i] heappush将值项推送到堆上，保持堆不变。通过上浮操作，插入的新元素逐层与父节点比较并交换，直到找到合适的位置，最终保持了最小堆的性质。 假设我们有一个当前的最小堆： 3 / \\ 5 7 / \\ / \\ 8 10 12 15 它在数组中的表示为：\n[3, 5, 7, 8, 10, 12, 15] 现在我们要插入一个新元素 4，插入过程如下：\n步骤 1: 插入元素 首先，将元素 4 插入到堆的最后一个位置，保持堆的完全二叉树结构：\n3 / \\ 5 7 / \\ / \\ 8 10 12 15 / 4 对应的数组表示为：\n[3, 5, 7, 8, 10, 12, 15, 4] 步骤 2: 进行上浮操作 现在需要检查新插入的元素 4 是否破坏了堆的性质（即父节点的值是否仍然小于或等于子节点的值）。如果破坏了，需要进行上浮操作。\n4 的父节点是 8，而 4 \u0026lt; 8，所以需要交换 4 和 8： 3 / \\ 5 7 / \\ / \\ 4 10 12 15 / 8 对应的数组表示为：\n[3, 5, 7, 4, 10, 12, 15, 8] 步骤 3: 继续上浮 现在，4 的父节点是 5，而 4 \u0026lt; 5，所以继续交换 4 和 5：\n3 / \\ 4 7 / \\ / \\ 5 10 12 15 / 8 对应的数组表示为：\n[3, 4, 7, 5, 10, 12, 15, 8] 步骤 4: 上浮完成 此时，4 的父节点是 3，且 4 \u0026gt; 3，满足最小堆的性质，因此不需要再上浮了。 最终的堆结构为：\n3 / \\ 4 7 / \\ / \\ 5 10 12 15 / 8 对应的数组表示为：\n[3, 4, 7, 5, 10, 12, 15, 8] ","id":4,"section":"posts","summary":"\u003ch2 id=\"常见的基于股价变化构建网络的方式\"\u003e常见的基于股价变化构建网络的方式\u003c/h2\u003e\n\u003cp\u003eMantegna 最早将复杂网络研究方法引入股票市场，Barabasi 在 2003 年的研究中证实美国股票市场满足无标度网络性质。在国内股票市场的研究中，Huang 在 2009 年的研究中证实沪深 1080 只股票满足幂律分布，Mai 在 2014年的复杂网络系统研究表明沪深 300 的核心行业为工业，谢凌峰和陈志 2016 年的研究中表明在沪港通开通后网络的平均度和聚类系数都有了显著的上升。\u003c/p\u003e","tags":["Quant Knowledge","Algorithms"],"title":"Minimum spanning tree 1","uri":"https://zhoujb22.github.io/2024/10/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E5%8E%9F%E7%90%86%E4%B8%8E%E7%AE%97%E6%B3%95-1/","year":"2024"},{"content":"连接数据库 /c database_name pqsl -h -p -U name 创建数据库 CREATE DATABASE # 非常危险的命令行 DROP DATABASE 创建table CREATE TABLE name ( Column_name data_name constraints if any ); 查看创建表格的基本信息 插入/选择数据： 查看Table内容 表格排序、取unique值、匹配符合条件、布尔值 展示有限行 模式匹配、分组、函数、筛选 最大、最小、平均、近似函数 处理空值（NULL） 避免计算错误 时间处理 删除限制条件 删除表格行、增加限制条件 ALTER TABLE person DROP CONSTRAINT unique_email_address UNIQUE(email); \\d person ALTER TABLE person ADD UNIQUE(email); \\d person DELETE FROM person; 更新Table数据 处理primary key冲突 INSERT INTO person () VALUES () ON CONFLICT (列名) DO NOTHING; # conflict on unique column. INSERT INTO person () VALUES () ON CONFLICT (列名) DO UPDATING SET A=a, B=b; Inner Joins 只保留有交集的部分 Left Joins 保留左侧和交集部分 Delete foreign keys UUID in action CREATE TABLE car1 ( car_uid UUID NOT NULL PRIMARY KEY, make VARCHAR(50) NOT NULL, price NUMERIC(19,2) NOT NULL CHECK (price\u0026gt;0)); INSERT INTO car1 (car_uid, make , price) VALUES (uuid_generate_v4(), 'Benz', '10000.00'); SELECT * FROM person JOIN car USING(car_uid); // 相同列 Output CSV ","id":5,"section":"posts","summary":"\u003ch2 id=\"连接数据库\"\u003e连接数据库\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-psql\"\u003e/c database_name\n\npqsl -h -p -U name\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"创建数据库\"\u003e创建数据库\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-psql\"\u003eCREATE DATABASE\n# 非常危险的命令行\nDROP DATABASE\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"创建table\"\u003e创建table\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-psql\"\u003eCREATE TABLE name (\nColumn_name data_name constraints if any\n);\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"查看创建表格的基本信息\"\u003e查看创建表格的基本信息\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/3797c539861dd528a6fa10864e53d0c9.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2 id=\"插入选择数据\"\u003e插入/选择数据：\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/f84ce471ff4b67fc8ad46e566b178ae4.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2 id=\"查看table内容\"\u003e查看Table内容\u003c/h2\u003e\n\u003ch2 id=\"表格排序取unique值匹配符合条件布尔值\"\u003e表格排序、取unique值、匹配符合条件、布尔值\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/78a8e32d04816f2b863c9099b1f35898.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2 id=\"展示有限行\"\u003e展示有限行\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/6e74de7df3a28282f0b03056850b6b11.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2 id=\"模式匹配分组函数筛选\"\u003e模式匹配、分组、函数、筛选\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/5acaceecea3dcedb9901b4999a19b8e3.png\" alt=\"\"\u003e\n\u003cimg src=\"/images/3823fac4613ae67ac27adfc0d07d3355.png\" alt=\"\"\u003e\n\u003cimg src=\"/images/639b1b2d6041aeee41ea66340941f585.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2 id=\"最大最小平均近似函数\"\u003e最大、最小、平均、近似函数\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/a0b6a0a09d2e9afa2544bd65c19ccf45.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2 id=\"处理空值null\"\u003e处理空值（NULL）\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/402d1e1ac463af166c385adba0537247.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2 id=\"避免计算错误\"\u003e避免计算错误\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/83a4b2f676e295af2fc8231bc807e1d5.png\" alt=\"\"\u003e\n\u003cimg src=\"/images/46a8ca2a064ff008c7eb4203de8fcd52.png\" alt=\"\"\u003e\n\u003cimg src=\"/images/d61fd44adf54d4c7cce5a892bedf8f8f.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2 id=\"时间处理\"\u003e时间处理\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/f48aafde9e252a1154126f7e21f3b44b.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2 id=\"删除限制条件\"\u003e删除限制条件\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/5b6a3cdf1fc95d421ceaf2e2f89bb853.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2 id=\"删除表格行增加限制条件\"\u003e删除表格行、增加限制条件\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/0ca1f21d0667a8e11daa84b83c105b08.png\" alt=\"\"\u003e\n\u003cimg src=\"/images/f1e72063fc6d340b94455b27d4406f74.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sql\"\u003eALTER TABLE person DROP CONSTRAINT unique_email_address UNIQUE(email);\n\\d person\nALTER TABLE person ADD UNIQUE(email);\n\\d person\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-sql\"\u003eDELETE FROM person;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"更新table数据\"\u003e更新Table数据\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/b5ca6835144cff670b3c34c0e1dcd401.png\" alt=\"\"\u003e\u003c/p\u003e","tags":["Quant Skills","SQL"],"title":"Database Command 1","uri":"https://zhoujb22.github.io/2024/10/database/","year":"2024"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating. — Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Inline Markdown In Table italics bold strikethrough code Code Blocks Code block with backticks html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Item First Sub-item Second Sub-item Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":6,"section":"posts","summary":"\u003cp\u003eThis article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\u003c/p\u003e","tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"https://zhoujb22.github.io/2019/03/markdown-syntax/","year":"2019"},{"content":"Hugo ships with several Built-in Shortcodes for rich content, along with a Privacy Config and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.\nInstagram Simple Shortcode View this post on Instagram YouTube Privacy Enhanced Shortcode Twitter Simple Shortcode Vimeo Simple Shortcode ","id":7,"section":"posts","summary":"\u003cp\u003eHugo ships with several \u003ca href=\"https://gohugo.io/content-management/shortcodes/#use-hugo-s-built-in-shortcodes\"\u003eBuilt-in Shortcodes\u003c/a\u003e for rich content, along with a \u003ca href=\"https://gohugo.io/about/hugo-and-gdpr/\"\u003ePrivacy Config\u003c/a\u003e and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.\u003c/p\u003e","tags":["shortcodes","privacy"],"title":"Rich Content","uri":"https://zhoujb22.github.io/2019/03/rich-content/","year":"2019"}],"tags":[{"title":"Algorithms","uri":"https://zhoujb22.github.io/tags/algorithms/"},{"title":"Css","uri":"https://zhoujb22.github.io/tags/css/"},{"title":"Html","uri":"https://zhoujb22.github.io/tags/html/"},{"title":"Index","uri":"https://zhoujb22.github.io/tags/index/"},{"title":"Markdown","uri":"https://zhoujb22.github.io/tags/markdown/"},{"title":"Privacy","uri":"https://zhoujb22.github.io/tags/privacy/"},{"title":"Quant Knowledge","uri":"https://zhoujb22.github.io/tags/quant-knowledge/"},{"title":"Quant Skills","uri":"https://zhoujb22.github.io/tags/quant-skills/"},{"title":"Readings","uri":"https://zhoujb22.github.io/tags/readings/"},{"title":"Shortcodes","uri":"https://zhoujb22.github.io/tags/shortcodes/"},{"title":"SQL","uri":"https://zhoujb22.github.io/tags/sql/"},{"title":"Themes","uri":"https://zhoujb22.github.io/tags/themes/"}]}